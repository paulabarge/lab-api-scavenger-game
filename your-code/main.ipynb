{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Scavenger Game\n",
    "\n",
    "## Challenge 1: Fork Languages\n",
    "\n",
    "You will find out how many programming languages are used among all the forks created from the main lab repo of your bootcamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paula, please enter your token here:········\n"
     ]
    }
   ],
   "source": [
    "#We import our github here and other libraries needed for the challenge\n",
    "import pandas as pd\n",
    "import re \n",
    "import numpy as np\n",
    "import getpass\n",
    "import requests\n",
    "import json\n",
    "username = 'paulabarge'\n",
    "token = getpass.getpass(prompt='Paula, please enter your token here:')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the main lab repo is ironhack-datalabs/madrid-oct-2018, you will:\n",
    "\n",
    "#### 1. Obtain the full list of forks created from the main lab repo via Github API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To list forks, we can use the GET method. As explained in the GitHub API documentation, we need to make the request to: GET /repos/:owner/:repo/forks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we request the Github API to list all the forks. \n",
    "\n",
    "url = \"https://api.github.com/repos/ironhack-datalabs/madrid-oct-2018/forks\"\n",
    "\n",
    "payload = {}\n",
    "headers= {}\n",
    "\n",
    "response = requests.get(url, auth=(username, token))\n",
    "\n",
    "#now we turn it into a json file \n",
    "response_dict = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "      \"id\": 204100911,\n",
      "      \"node_id\": \"MDEwOlJlcG9zaXRvcnkyMDQxMDA5MTE=\",\n",
      "      \"name\": \"mad-oct-2018\",\n",
      "      \"full_name\": \"rsennes/mad-oct-2018\",\n",
      "      \"private\": false,\n",
      "      \"owner\": {\n",
      "            \"login\": \"rsennes\",\n",
      "            \"id\": 34886384,\n",
      "            \"node_id\": \"MDQ6VXNlcjM0ODg2Mzg0\",\n",
      "            \"avatar_url\": \"https://avatars1.githubusercontent.com/u/34886384?v=4\",\n",
      "            \"gravatar_id\": \"\",\n",
      "            \"url\": \"https://api.github.com/users/rsennes\",\n",
      "            \"html_url\": \"https://github.com/rsennes\",\n",
      "            \"followers_url\": \"https://api.github.com/users/rsennes/followers\",\n",
      "            \"following_url\": \"https://api.github.com/users/rsennes/following{/other_user}\",\n",
      "            \"gists_url\": \"https://api.github.com/users/rsennes/gists{/gist_id}\",\n",
      "            \"starred_url\": \"https://api.github.com/users/rsennes/starred{/owner}{/repo}\",\n",
      "            \"subscriptions_url\": \"https://api.github.com/users/rsennes/subscriptions\",\n",
      "            \"organizations_url\": \"https://api.github.com/users/rsennes/orgs\",\n",
      "            \"repos_url\": \"https://api.github.com/users/rsennes/repos\",\n",
      "            \"events_url\": \"https://api.github.com/users/rsennes/events{/privacy}\",\n",
      "            \"received_events_url\": \"https://api.github.com/users/rsennes/received_events\",\n",
      "            \"type\": \"User\",\n",
      "            \"site_admin\": false\n",
      "      },\n",
      "      \"html_url\": \"https://github.com/rsennes/mad-oct-2018\",\n",
      "      \"description\": \"Student labs for Ironhack data analytics bootcamp\",\n",
      "      \"fork\": true,\n",
      "      \"url\": \"https://api.github.com/repos/rsennes/mad-oct-2018\",\n",
      "      \"forks_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/forks\",\n",
      "      \"keys_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/keys{/key_id}\",\n",
      "      \"collaborators_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/collaborators{/collaborator}\",\n",
      "      \"teams_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/teams\",\n",
      "      \"hooks_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/hooks\",\n",
      "      \"issue_events_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/issues/events{/number}\",\n",
      "      \"events_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/events\",\n",
      "      \"assignees_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/assignees{/user}\",\n",
      "      \"branches_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/branches{/branch}\",\n",
      "      \"tags_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/tags\",\n",
      "      \"blobs_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/git/blobs{/sha}\",\n",
      "      \"git_tags_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/git/tags{/sha}\",\n",
      "      \"git_refs_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/git/refs{/sha}\",\n",
      "      \"trees_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/git/trees{/sha}\",\n",
      "      \"statuses_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/statuses/{sha}\",\n",
      "      \"languages_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/languages\",\n",
      "      \"stargazers_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/stargazers\",\n",
      "      \"contributors_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/contributors\",\n",
      "      \"subscribers_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/subscribers\",\n",
      "      \"subscription_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/subscription\",\n",
      "      \"commits_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/commits{/sha}\",\n",
      "      \"git_commits_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/git/commits{/sha}\",\n",
      "      \"comments_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/comments{/number}\",\n",
      "      \"issue_comment_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/issues/comments{/number}\",\n",
      "      \"contents_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/contents/{+path}\",\n",
      "      \"compare_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/compare/{base}...{head}\",\n",
      "      \"merges_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/merges\",\n",
      "      \"archive_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/{archive_format}{/ref}\",\n",
      "      \"downloads_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/downloads\",\n",
      "      \"issues_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/issues{/number}\",\n",
      "      \"pulls_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/pulls{/number}\",\n",
      "      \"milestones_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/milestones{/number}\",\n",
      "      \"notifications_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/notifications{?since,all,participating}\",\n",
      "      \"labels_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/labels{/name}\",\n",
      "      \"releases_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/releases{/id}\",\n",
      "      \"deployments_url\": \"https://api.github.com/repos/rsennes/mad-oct-2018/deployments\",\n",
      "      \"created_at\": \"2019-08-24T03:04:02Z\",\n",
      "      \"updated_at\": \"2019-08-24T03:04:04Z\",\n",
      "      \"pushed_at\": \"2019-08-19T11:16:55Z\",\n",
      "      \"git_url\": \"git://github.com/rsennes/mad-oct-2018.git\",\n",
      "      \"ssh_url\": \"git@github.com:rsennes/mad-oct-2018.git\",\n",
      "      \"clone_url\": \"https://github.com/rsennes/mad-oct-2018.git\",\n",
      "      \"svn_url\": \"https://github.com/rsennes/mad-oct-2018\",\n",
      "      \"homepage\": \"\",\n",
      "      \"size\": 116995,\n",
      "      \"stargazers_count\": 0,\n",
      "      \"watchers_count\": 0,\n",
      "      \"language\": \"Jupyter Notebook\",\n",
      "      \"has_issues\": false,\n",
      "      \"has_projects\": true,\n",
      "      \"has_downloads\": true,\n",
      "      \"has_wiki\": true,\n",
      "      \"has_pages\": false,\n",
      "      \"forks_count\": 0,\n",
      "      \"mirror_url\": null,\n",
      "      \"archived\": false,\n",
      "      \"disabled\": false,\n",
      "      \"open_issues_count\": 0,\n",
      "      \"license\": {\n",
      "            \"key\": \"unlicense\",\n",
      "            \"name\": \"The Unlicense\",\n",
      "            \"spdx_id\": \"Unlicense\",\n",
      "            \"url\": \"https://api.github.com/licenses/unlicense\",\n",
      "            \"node_id\": \"MDc6TGljZW5zZTE1\"\n",
      "      },\n",
      "      \"forks\": 0,\n",
      "      \"open_issues\": 0,\n",
      "      \"watchers\": 0,\n",
      "      \"default_branch\": \"master\",\n",
      "      \"permissions\": {\n",
      "            \"admin\": false,\n",
      "            \"push\": false,\n",
      "            \"pull\": true\n",
      "      }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(response_dict[1], indent=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Loop the JSON response to find out the language attribute of each fork. Use an array to store the language attributes of each fork.\n",
    "Hint: Each language should appear only once in your array.\n",
    "Print the language array. It should be something like: [\"Jupyter Notebook\", \"HTML\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the languages used: [None, 'Jupyter Notebook', 'Jupyter Notebook', 'Jupyter Notebook', 'Jupyter Notebook', 'Jupyter Notebook', 'HTML', 'Jupyter Notebook', 'Jupyter Notebook', 'Jupyter Notebook', 'Jupyter Notebook', 'Jupyter Notebook', 'Jupyter Notebook', 'Jupyter Notebook', 'Jupyter Notebook']\n"
     ]
    }
   ],
   "source": [
    "# First we look for the key languages\n",
    "response_dict[0].keys()\n",
    "# Let's prove that it is what we are looking for \n",
    "response_dict[1][\"language\"]\n",
    "\n",
    "range(len(response_dict)) #there are 15 rows, 15 dictionaries different\n",
    "languages_list = []\n",
    "for x in range(len(response_dict)):\n",
    "    languages = response_dict[x][\"language\"]\n",
    "    languages_list.append(languages)\n",
    "\n",
    "print(\"These are the languages used:\", languages_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: Count Commits\n",
    "Count how many commits were made in the month of october of 2018.\n",
    "#### 1. Obtain all the commits made in October 2018 via API, which is a JSON array that contains multiple commit objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://api.github.com/repos/ironhack-datalabs/madrid-oct-2018/commits\"\n",
    "\n",
    "payload = {}\n",
    "headers= {}\n",
    "\n",
    "response = requests.get(url, auth=(username, token))\n",
    "response_dict = response.json()\n",
    "len(response_dict)\n",
    "\n",
    "#Since Github has 30 predefined per page, lets set this up to 100 to see if we have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'next': {'url': 'https://api.github.com/repositories/153720804/commits?per_page=100&page=2',\n",
       "  'rel': 'next'},\n",
       " 'last': {'url': 'https://api.github.com/repositories/153720804/commits?per_page=100&page=4',\n",
       "  'rel': 'last'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://api.github.com/repos/ironhack-datalabs/madrid-oct-2018/commits?per_page=100\"\n",
    "\n",
    "payload = {}\n",
    "headers= {}\n",
    "\n",
    "response = requests.get(url, auth=(username, token))\n",
    "response_dict = response.json()\n",
    "len(response_dict)\n",
    "\n",
    "#Let's check now how many pages are there.\n",
    "\n",
    "response.links\n",
    "#There are 4 pages. There are at least more than 300 commits and less than 400. Let's find out the number of total commits done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.github.com/repositories/153720804/commits?per_page=100&page=4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://api.github.com/repos/ironhack-datalabs/madrid-oct-2018/commits?per_page=100&page=\"\n",
    "\n",
    "payload = {}\n",
    "headers= {}\n",
    "\n",
    "response = requests.get(url, auth=(username, token))\n",
    "response_dict = response.json()\n",
    "\n",
    "response.links[\"last\"][\"url\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Count how many commit objects are contained in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'last'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6aec013b6474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnumber_commits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnumber_of_pages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(?<=&page=)\\d+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"last\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#findall and lookbehinf to find every digit after &page=\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'last'"
     ]
    }
   ],
   "source": [
    "#applying pagination\n",
    "\n",
    "number_commits = [] \n",
    "\n",
    "number_of_pages = int(re.findall(\"(?<=&page=)\\d+\",response.links[\"last\"][\"url\"])[0])\n",
    "#findall and lookbehinf to find every digit after &page=\n",
    "\n",
    "full_response = []\n",
    "#if there are 4 pages then look for all of them and add it to the original url \"https://api.github.com/repos/ironhack-datalabs/madrid-oct-2018/commits?per_page=100&page=\"\n",
    "for page in range(1, number_of_pages+1):\n",
    "    #concatenating the url to each of the pages\n",
    "    url = \"https://api.github.com/repos/ironhack-datalabs/madrid-oct-2018/commits?per_page=100&page=\" + str(page)\n",
    "    payload = {}\n",
    "    headers= {}\n",
    "\n",
    "    response = requests.get(url, auth=(username, token)).json()\n",
    "    #putting every response to count the amount of commits\n",
    "    full_response = full_response + response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are: 400 commits\n"
     ]
    }
   ],
   "source": [
    "print(\"There are:\",len(full_response), \"commits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3: Hidden Cold Joke\n",
    "\n",
    "Using Python, call Github API to find out the cold joke contained in the 24 secret files in the following repo:\n",
    "\n",
    "https://github.com/ironhack-datalabs/scavenger\n",
    "\n",
    "The filenames of the secret files contain .scavengerhunt and they are scattered in different directories of this repo. The secret files are named from .0001.scavengerhunt to .0024.scavengerhunt. They are scattered randomly throughout this repo. You need to search for these files by calling the Github API, not searching the local files on your computer.\n",
    "\n",
    "#### 1. Find the secret files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we make a request to discover the content in the repository\n",
    "\n",
    "url = \"https://api.github.com/repos/ironhack-datalabs/scavenger/contents/\"\n",
    "\n",
    "payload = {}\n",
    "headers= {}\n",
    "\n",
    "response = requests.get(url, auth=(username, token))\n",
    "response_json = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we check the lenght \n",
    "len(response_json)\n",
    "#We get 26 folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to access to each of the folders. If we check the keys of the dict, we can then understand the name of each of the folder\n",
    "response_json[1][\"name\"]\n",
    "\n",
    "#for each of the 26, lets get the name of the folders:\n",
    "folder_name =[] #creating an empty list to store all the folder names \n",
    "for numfolder in range(1,len(response_json)): #for range from 0 to 26\n",
    "    name= response_json[numfolder][\"name\"]\n",
    "    folder_name.append(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15024',\n",
       " '15534',\n",
       " '17020',\n",
       " '30351',\n",
       " '40303',\n",
       " '44639',\n",
       " '45525',\n",
       " '47222',\n",
       " '47830',\n",
       " '49418',\n",
       " '50896',\n",
       " '55417',\n",
       " '55685',\n",
       " '60224',\n",
       " '64880',\n",
       " '66032',\n",
       " '68848',\n",
       " '70751',\n",
       " '70985',\n",
       " '88596',\n",
       " '89046',\n",
       " '89338',\n",
       " '91701',\n",
       " '97881',\n",
       " '98750']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name #list with the names of all the folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 25)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(folder_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have to add this to the URL to access to each of the folders\n",
    "\n",
    "full_dictionary = [] #this empty list will store all the json files for each of the folders in the scavenger folder \n",
    "\n",
    "for folder in range(len(folder_name)): #from 0 to 25, concatenate the url to the name of the folder in that index range\n",
    "    url = \"https://api.github.com/repos/ironhack-datalabs/scavenger/contents/\" + str(folder_name[folder])\n",
    "\n",
    "    payload = {}\n",
    "    headers= {}\n",
    "\n",
    "    response = requests.get(url, auth=(username, token)).json()\n",
    "    #added to a dictionary\n",
    "    full_dictionary = full_dictionary + response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '.0006.scavengerhunt',\n",
       " 'path': '15024/.0006.scavengerhunt',\n",
       " 'sha': '1c9064284a24b3486015eafdb391b141c27ada2b',\n",
       " 'size': 3,\n",
       " 'url': 'https://api.github.com/repos/ironhack-datalabs/scavenger/contents/15024/.0006.scavengerhunt?ref=master',\n",
       " 'html_url': 'https://github.com/ironhack-datalabs/scavenger/blob/master/15024/.0006.scavengerhunt',\n",
       " 'git_url': 'https://api.github.com/repos/ironhack-datalabs/scavenger/git/blobs/1c9064284a24b3486015eafdb391b141c27ada2b',\n",
       " 'download_url': 'https://raw.githubusercontent.com/ironhack-datalabs/scavenger/master/15024/.0006.scavengerhunt',\n",
       " 'type': 'file',\n",
       " '_links': {'self': 'https://api.github.com/repos/ironhack-datalabs/scavenger/contents/15024/.0006.scavengerhunt?ref=master',\n",
       "  'git': 'https://api.github.com/repos/ironhack-datalabs/scavenger/git/blobs/1c9064284a24b3486015eafdb391b141c27ada2b',\n",
       "  'html': 'https://github.com/ironhack-datalabs/scavenger/blob/master/15024/.0006.scavengerhunt'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dictionary[0]\n",
    "#Now we are in the path for each of the folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.  Sort the filenames ascendingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now among all the files in full_dictionary we need to find those \"names\" that start with '.00' \n",
    "\n",
    "full_dictionary[0][\"path\"]\n",
    "full_dictionary[82][\"path\"]\n",
    "\n",
    "#Let's create a list with all the file names:\n",
    "secret_file_path = [full_dictionary[i][\"path\"] for i in range(len(full_dictionary))]\n",
    "secret_file_path\n",
    "\n",
    "#We just want to access those files that are secret, so let's clean the paths that we don't need\n",
    "secret_files = []\n",
    "\n",
    "for filename in secret_file_path:\n",
    "    if \"scavengerhunt\" in filename:\n",
    "        secret_files.append(filename)\n",
    "\n",
    "#let's delete the folder names and sort the file names \n",
    "secret_files_sorted = []\n",
    "\n",
    "secret_files\n",
    "\n",
    "dictionary = {}\n",
    "for i in secret_files:\n",
    "    a, b = i.split('/')\n",
    "    dictionary[a] = b\n",
    "    \n",
    "dictionary\n",
    "sorted_dict = dict(sorted(dictionary.items(), key= lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".0001.scavengerhunt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('98750', '.0001.scavengerhunt'),\n",
       " ('88596', '.0002.scavengerhunt'),\n",
       " ('60224', '.0003.scavengerhunt'),\n",
       " ('68848', '.0004.scavengerhunt'),\n",
       " ('44639', '.0005.scavengerhunt'),\n",
       " ('15024', '.0006.scavengerhunt'),\n",
       " ('17020', '.0007.scavengerhunt'),\n",
       " ('97881', '.0009.scavengerhunt'),\n",
       " ('47830', '.0010.scavengerhunt'),\n",
       " ('50896', '.0011.scavengerhunt'),\n",
       " ('15534', '.0012.scavengerhunt'),\n",
       " ('89338', '.0013.scavengerhunt'),\n",
       " ('49418', '.0014.scavengerhunt'),\n",
       " ('91701', '.0015.scavengerhunt'),\n",
       " ('70985', '.0017.scavengerhunt'),\n",
       " ('45525', '.0018.scavengerhunt'),\n",
       " ('70751', '.0019.scavengerhunt'),\n",
       " ('55685', '.0020.scavengerhunt'),\n",
       " ('30351', '.0021.scavengerhunt'),\n",
       " ('40303', '.0022.scavengerhunt'),\n",
       " ('55417', '.0023.scavengerhunt'),\n",
       " ('47222', '.0024.scavengerhunt')]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = list(sorted_dict.items())\n",
    "print(lst[0][1])\n",
    "len(lst)\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['98750/.0001.scavengerhunt',\n",
       " '88596/.0002.scavengerhunt',\n",
       " '60224/.0003.scavengerhunt',\n",
       " '68848/.0004.scavengerhunt',\n",
       " '44639/.0005.scavengerhunt',\n",
       " '15024/.0006.scavengerhunt',\n",
       " '17020/.0007.scavengerhunt',\n",
       " '97881/.0009.scavengerhunt',\n",
       " '47830/.0010.scavengerhunt',\n",
       " '50896/.0011.scavengerhunt',\n",
       " '15534/.0012.scavengerhunt',\n",
       " '89338/.0013.scavengerhunt',\n",
       " '49418/.0014.scavengerhunt',\n",
       " '91701/.0015.scavengerhunt',\n",
       " '70985/.0017.scavengerhunt',\n",
       " '45525/.0018.scavengerhunt',\n",
       " '70751/.0019.scavengerhunt',\n",
       " '55685/.0020.scavengerhunt',\n",
       " '30351/.0021.scavengerhunt',\n",
       " '40303/.0022.scavengerhunt',\n",
       " '55417/.0023.scavengerhunt',\n",
       " '47222/.0024.scavengerhunt']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst1 = []\n",
    "for x,y in lst:\n",
    "    lst1.append(x+\"/\"+y)\n",
    "lst1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Read the content of each secret files into an array of strings.\n",
    "Since the response is encoded, you will need to send the following information in the header of your request:\n",
    "````python\n",
    "headers = {'Accept': 'application/vnd.github.v3.raw'}\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'data',\n",
       " 'science,',\n",
       " '80',\n",
       " 'percent',\n",
       " 'of',\n",
       " 'time',\n",
       " 'is',\n",
       " 'preparing',\n",
       " 'data,',\n",
       " '20',\n",
       " 'percent',\n",
       " 'of',\n",
       " 'time',\n",
       " 'spent',\n",
       " 'complaining',\n",
       " 'about',\n",
       " 'the',\n",
       " 'need',\n",
       " 'to',\n",
       " 'prepare',\n",
       " 'data.']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Secret_joke = []\n",
    "for i in lst1:\n",
    "    \n",
    "    url = 'https://api.github.com/repos/ironhack-datalabs/scavenger/contents/'+i\n",
    "    \n",
    "    headers = {'Accept': 'application/vnd.github.v3.raw'}\n",
    "    response = requests.get(url, auth=(username, token), headers=headers)\n",
    "    \n",
    "    word = response.text\n",
    "    Secret_joke.append(word.replace('\\n', ''))\n",
    "    \n",
    "Secret_joke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Concatenate the strings in the array separating each two with a whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "Secret_joke\n",
    "joke = \" \".join(Secret_joke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Print out the joke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In data science, 80 percent of time is preparing data, 20 percent of time spent complaining about the need to prepare data.\n"
     ]
    }
   ],
   "source": [
    "print(joke)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
